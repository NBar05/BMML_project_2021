{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c24e72f",
   "metadata": {
    "cellId": "dfqjhac6kpxis7erwok18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -q torch --upgrade\n",
    "%pip install -q foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68dc0c6b",
   "metadata": {
    "cellId": "045kspcrzbjxdb40jkcn124"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch import linalg\n",
    "from torch.optim import SGD, Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "import foolbox as fb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils_ods_attack import ods_attack\n",
    "from utils_general import train, test, short_test\n",
    "from utils_attacks import whitebox_attack, blackbox_attack_steps\n",
    "from utils_data import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0dc33",
   "metadata": {
    "cellId": "9e9l36kp6kcez3njnaa2eo"
   },
   "outputs": [],
   "source": [
    "# reproducibility issues\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f8e09",
   "metadata": {
    "cellId": "31o5rvk6zc3ir1ulcbloes"
   },
   "outputs": [],
   "source": [
    "# !unzip tiny-imagenet-200.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c927586",
   "metadata": {
    "cellId": "2o51vdyu2bguwq0ib1gwm"
   },
   "outputs": [],
   "source": [
    "DATA_NAME = 'cifar'\n",
    "\n",
    "if DATA_NAME == 'imagenet':\n",
    "    path = 'tiny-imagenet-200/'\n",
    "    \n",
    "    data_loader_train = get_dataloader(path, 'train', batch_size=128)\n",
    "    data_loader_valid = get_dataloader(path, 'valid', batch_size=128)\n",
    "    data_loader_test = get_dataloader(path, 'test', batch_size=128)\n",
    "    \n",
    "    NUM_OF_CLASSES = 200\n",
    "    \n",
    "else:\n",
    "    dataset_cifar_train = datasets.CIFAR100(\n",
    "        root=\"./\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "    )\n",
    "    dataset_cifar_valid_test = datasets.CIFAR100(\n",
    "        root=\"./\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "    )\n",
    "\n",
    "    dataset_cifar_valid, dataset_cifar_test = torch.utils.data.random_split(dataset_cifar_valid_test, [5000, 5000], \n",
    "                                                                            generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    data_loader_train = DataLoader(dataset_cifar_train, batch_size=128, shuffle=True)\n",
    "    data_loader_valid = DataLoader(dataset_cifar_valid, batch_size=128, shuffle=False)\n",
    "    data_loader_test = DataLoader(dataset_cifar_test, batch_size=128, shuffle=False)\n",
    "    \n",
    "    NUM_OF_CLASSES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01115f2c",
   "metadata": {
    "cellId": "rizg7g0imxnmfyl3xu6n9"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'resnet50' # change name here if you change the model in the following class\n",
    "\n",
    "class OurResNetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Small class to initialize ResNet\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, pretrained_bool, num_of_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_resnet = models.resnet50(pretrained=pretrained_bool) # 18 34 50 101 152\n",
    "        self.model_resnet.fc = nn.Linear(self.model_resnet.fc.in_features, num_of_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model_resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0198f051",
   "metadata": {
    "cellId": "i7xs6yepnl3la74idfyao"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# optimzer and scheduler params\n",
    "learning_rate_, weight_decay_ = 0.01, 0.001\n",
    "step_size_, gamma_ = 3, 0.7\n",
    "\n",
    "# level of noise, and ODS params\n",
    "noise_sd_, nu_, num_of_steps_ = 0.1, 0.1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1321945b",
   "metadata": {
    "cellId": "tn4xvfuh0e2e7qq7vva19"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = OurResNetModel(True, NUM_OF_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=learning_rate_, momentum=0.0, weight_decay=weight_decay_)\n",
    "scheduler = StepLR(optimizer, step_size=step_size_, gamma=gamma_)\n",
    "\n",
    "valid_loss_, valid_acc_ = 0, 0\n",
    "for epoch in range(10):\n",
    "    print(f'Epoch {epoch + 1}\\n')\n",
    "    train_loss, train_acc = train(data_loader_train, model, criterion, optimizer, device=device,\n",
    "                                  augment=False, noise_sd=noise_sd_, attack=False, nu=nu_, num_of_steps=num_of_steps_) # ; print()\n",
    "    valid_loss, valid_acc = test(data_loader_valid, model, criterion, device=device,\n",
    "                                 augment=False, noise_sd=noise_sd_, attack=False, nu=nu_, num_of_steps=num_of_steps_); print()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if valid_acc > valid_acc_ * 1.01:\n",
    "        valid_acc_ = valid_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, os.path.join(f'checkpoint_{DATA_NAME}_{MODEL_NAME}_baseline_eps03.pth.tar'))\n",
    "    else:\n",
    "        print(\"Early stopping\")\n",
    "        checkpoint = torch.load(f'checkpoint_{DATA_NAME}_{MODEL_NAME}_baseline_eps03.pth.tar')\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        break\n",
    "\n",
    "model.to(torch.device('cpu')); print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f878340",
   "metadata": {
    "cellId": "d8fc1l9ghrtna1i781lx8"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'Accuracy on train set: {short_test(data_loader_train, model, device=device)}%')\n",
    "print(f'Accuracy on valid set: {short_test(data_loader_valid, model, device=device)}%')\n",
    "print(f'Accuracy on test  set: {short_test(data_loader_test, model, device=device)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233cb09e",
   "metadata": {
    "cellId": "xqoc13fgbwd4428v51uyo"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "del model, criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d1f21f",
   "metadata": {
    "cellId": "htqscikwsohn163lfwvf1a"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = OurResNetModel(True, NUM_OF_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=learning_rate_, momentum=0.0, weight_decay=weight_decay_)\n",
    "scheduler = StepLR(optimizer, step_size=step_size_, gamma=gamma_)\n",
    "\n",
    "valid_loss_, valid_acc_ = 0, 0\n",
    "for epoch in range(10):\n",
    "    print(f'Epoch {epoch + 1}\\n')\n",
    "    train_loss, train_acc = train(data_loader_train, model, criterion, optimizer, device=device,\n",
    "                                  augment=True, noise_sd=noise_sd_, attack=False, nu=nu_, num_of_steps=num_of_steps_) # ; print()\n",
    "    valid_loss, valid_acc = test(data_loader_valid, model, criterion, device=device,\n",
    "                                 augment=True, noise_sd=noise_sd_, attack=False, nu=nu_, num_of_steps=num_of_steps_); print()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if valid_acc > valid_acc_ * 1.01:\n",
    "        valid_acc_ = valid_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, os.path.join(f'checkpoint_{DATA_NAME}_{MODEL_NAME}_pixeldp_eps03.pth.tar'))\n",
    "    else:\n",
    "        print(\"Early stopping\")\n",
    "        checkpoint = torch.load(f'checkpoint_{DATA_NAME}_{MODEL_NAME}_pixeldp_eps03.pth.tar')\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        break\n",
    "\n",
    "model.to(torch.device('cpu')); print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df8e9d",
   "metadata": {
    "cellId": "ruyo7etplgivgixl8tgrv"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'Accuracy on train set: {short_test(data_loader_train, model, device=device)}%')\n",
    "print(f'Accuracy on valid set: {short_test(data_loader_valid, model, device=device)}%')\n",
    "print(f'Accuracy on test  set: {short_test(data_loader_test, model, device=device)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b390c05",
   "metadata": {
    "cellId": "azw91d1hcq87f98gnjnbhr"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "del model, criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ce1f7",
   "metadata": {
    "cellId": "th5f5mxh5yp8qcbocdf5"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = OurResNetModel(True, NUM_OF_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=learning_rate_, momentum=0.0, weight_decay=weight_decay_)\n",
    "scheduler = StepLR(optimizer, step_size=step_size_, gamma=gamma_)\n",
    "\n",
    "valid_loss_, valid_acc_ = 0, 0\n",
    "for epoch in range(10):\n",
    "    print(f'Epoch {epoch + 1}\\n')\n",
    "    train_loss, train_acc = train(data_loader_train, model, criterion, optimizer, device=device,\n",
    "                                  augment=True, noise_sd=noise_sd_, attack=True, nu=nu_, num_of_steps=num_of_steps_) # ; print()\n",
    "    valid_loss, valid_acc = test(data_loader_valid, model, criterion, device=device,\n",
    "                                 augment=True, noise_sd=noise_sd_, attack=True, nu=nu_, num_of_steps=num_of_steps_); print()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if valid_acc > valid_acc_ * 1.01:\n",
    "        valid_acc_ = valid_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, os.path.join(f'checkpoint_{DATA_NAME}_{MODEL_NAME}_ods_eps03.pth.tar'))\n",
    "    else:\n",
    "        print(\"Early stopping\")\n",
    "        checkpoint = torch.load(f'checkpoint_{DATA_NAME}_{MODEL_NAME}_ods_eps03.pth.tar')\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        break\n",
    "\n",
    "model.to(torch.device('cpu')); print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1d16b5",
   "metadata": {
    "cellId": "gnt8c20rf9w71mk1qlnhl7"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'Accuracy on train set: {short_test(data_loader_train, model, device=device)}%')\n",
    "print(f'Accuracy on valid set: {short_test(data_loader_valid, model, device=device)}%')\n",
    "print(f'Accuracy on test  set: {short_test(data_loader_test, model, device=device)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9561cf6",
   "metadata": {
    "cellId": "nyokkyq38x71j0a360atxd",
    "execution_id": "6f02d34c-3412-4dd4-86c2-9f39ef4812e9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "del model, criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc52f5e1",
   "metadata": {
    "cellId": "5ehfi9je0nt9khwohux12t"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "1c3378ce-142e-4a2c-ae80-8dfeafd77318",
  "notebookPath": "code_training_models.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
